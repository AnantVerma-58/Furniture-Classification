{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform import convert_images\n",
    "from augment import augment_images\n",
    "from split import split_dataset\n",
    "from utils import input_folder, output_folder,augment_folder, final_data_folder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory created: /home/anant/anaconda3/envs/class/project/updated_furnture_data\n",
      "Output directory created: /home/anant/anaconda3/envs/class/project/augmented\n"
     ]
    }
   ],
   "source": [
    "convert_images(input_folder, output_folder, target_format=\".jpeg\")\n",
    "augment_images(output_folder, augment_folder, target_size=(256, 256), target_format=\".jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed class: table, 48 train, 6 val, 6 test\n",
      "Processed class: chair, 43 train, 5 val, 6 test\n",
      "Processed class: bed, 48 train, 6 val, 6 test\n",
      "Processed class: storage, 48 train, 6 val, 6 test\n",
      "Processed class: sofa, 48 train, 6 val, 6 test\n"
     ]
    }
   ],
   "source": [
    "split_dataset(augment_folder, final_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from transform import transform\n",
    "import time\n",
    "import os\n",
    "from utils import final_data_folder\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of the image before transformation: <class 'torch.Tensor'>\n",
      "Shape of the image before transformation: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image (optional, based on model input)\n",
    "    transforms.ToTensor(),  # Convert to Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(root=os.path.join(final_data_folder, 'train'), transform=transform)\n",
    "test_data = datasets.ImageFolder(root=os.path.join(final_data_folder, 'test'), transform=transform)\n",
    "val_data = datasets.ImageFolder(root=os.path.join(final_data_folder, 'val'), transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "sample_image, label = train_data[0]\n",
    "\n",
    "# Print out the type of the image\n",
    "print(f\"Type of the image before transformation: {type(sample_image)}\")\n",
    "print(f\"Shape of the image before transformation: {np.array(sample_image).shape if isinstance(sample_image, Image.Image) else sample_image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create models\n",
    "def create_model(model_name, num_classes=10):\n",
    "    \"\"\"\n",
    "    Create and return a model based on the name and number of output classes.\n",
    "    \"\"\"\n",
    "    if model_name == 'resnet':\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights)  # ResNet18 (can use ResNet50, ResNet101 as well)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)  # Modify final layer for custom classes\n",
    "    \n",
    "    elif model_name == 'vgg16':\n",
    "        model = models.vgg16(weights=models.VGG16_Weights)  # VGG16\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)  # Modify final layer\n",
    "    \n",
    "    elif model_name == 'densenet':\n",
    "        model = models.densenet201(weights=models.DenseNet201_Weights)  # DenseNet121\n",
    "        model.classifier = nn.Linear(model.classifier.in_features, num_classes)  # Modify final layer\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "    \n",
    "    # Freeze all layers except the last ones\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False  # Freeze all layers\n",
    "    \n",
    "    # Unfreeze the last layer\n",
    "    if model_name == 'resnet':\n",
    "        model.fc.weight.requires_grad = True\n",
    "    elif model_name == 'vgg16':\n",
    "        model.classifier[6].weight.requires_grad = True\n",
    "    elif model_name == 'inceptionv3':\n",
    "        model.fc.weight.requires_grad = True\n",
    "    elif model_name == 'densenet':\n",
    "        model.classifier.weight.requires_grad = True\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train a model\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    \"\"\"\n",
    "    Train the given model on the dataset.\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = 100 * correct / total\n",
    "        epoch_time = end_time - start_time\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%, Time: {epoch_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model\n",
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test set.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training densenet model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anant/anaconda3/envs/class/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Loss: 1.4249, Accuracy: 41.20%, Time: 3.62s\n",
      "Epoch 2/30 - Loss: 0.9215, Accuracy: 87.68%, Time: 3.32s\n",
      "Epoch 3/30 - Loss: 0.5774, Accuracy: 96.48%, Time: 3.33s\n",
      "Epoch 4/30 - Loss: 0.3995, Accuracy: 96.83%, Time: 3.33s\n",
      "Epoch 5/30 - Loss: 0.3107, Accuracy: 98.24%, Time: 3.32s\n",
      "Epoch 6/30 - Loss: 0.2590, Accuracy: 98.94%, Time: 3.34s\n",
      "Epoch 7/30 - Loss: 0.2025, Accuracy: 98.94%, Time: 3.35s\n",
      "Epoch 8/30 - Loss: 0.1663, Accuracy: 99.65%, Time: 3.34s\n",
      "Epoch 9/30 - Loss: 0.1410, Accuracy: 99.30%, Time: 3.36s\n",
      "Epoch 10/30 - Loss: 0.1280, Accuracy: 99.30%, Time: 3.34s\n",
      "Epoch 11/30 - Loss: 0.1320, Accuracy: 100.00%, Time: 3.35s\n",
      "Epoch 12/30 - Loss: 0.0939, Accuracy: 100.00%, Time: 3.35s\n",
      "Epoch 13/30 - Loss: 0.0860, Accuracy: 100.00%, Time: 3.37s\n",
      "Epoch 14/30 - Loss: 0.0759, Accuracy: 100.00%, Time: 3.38s\n",
      "Epoch 15/30 - Loss: 0.0781, Accuracy: 100.00%, Time: 3.36s\n",
      "Epoch 16/30 - Loss: 0.0816, Accuracy: 99.30%, Time: 3.37s\n",
      "Epoch 17/30 - Loss: 0.0707, Accuracy: 100.00%, Time: 3.39s\n",
      "Epoch 18/30 - Loss: 0.0679, Accuracy: 99.30%, Time: 3.39s\n",
      "Epoch 19/30 - Loss: 0.0627, Accuracy: 100.00%, Time: 3.38s\n",
      "Epoch 20/30 - Loss: 0.0532, Accuracy: 100.00%, Time: 3.42s\n",
      "Epoch 21/30 - Loss: 0.0503, Accuracy: 100.00%, Time: 3.43s\n",
      "Epoch 22/30 - Loss: 0.0491, Accuracy: 100.00%, Time: 3.38s\n",
      "Epoch 23/30 - Loss: 0.0395, Accuracy: 100.00%, Time: 3.52s\n",
      "Epoch 24/30 - Loss: 0.0399, Accuracy: 100.00%, Time: 3.39s\n",
      "Epoch 25/30 - Loss: 0.0411, Accuracy: 100.00%, Time: 3.47s\n",
      "Epoch 26/30 - Loss: 0.0378, Accuracy: 100.00%, Time: 3.49s\n",
      "Epoch 27/30 - Loss: 0.0388, Accuracy: 100.00%, Time: 3.55s\n",
      "Epoch 28/30 - Loss: 0.0386, Accuracy: 100.00%, Time: 3.47s\n",
      "Epoch 29/30 - Loss: 0.0321, Accuracy: 100.00%, Time: 3.48s\n",
      "Epoch 30/30 - Loss: 0.0290, Accuracy: 100.00%, Time: 3.50s\n",
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# device = 'cpu'\n",
    "# Main function to train and evaluate models\n",
    "def main():\n",
    "    # model_names = ['resnet', 'vgg16', 'densenet']  # List of models to train\n",
    "    model_names = ['densenet']\n",
    "    num_classes = 5\n",
    "\n",
    "    for model_name in model_names:\n",
    "        print(f\"\\nTraining {model_name} model:\")\n",
    "        \n",
    "        model = create_model(model_name, num_classes=num_classes)\n",
    "        model = model.to(device)\n",
    "\n",
    "        # Loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "        if not trainable_params:\n",
    "            raise ValueError(\"No trainable parameters found. Make sure final layers are unfrozen.\")\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = optim.Adam(trainable_params, lr=0.001)\n",
    "        # optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "\n",
    "        # Train the model\n",
    "        train_model(model, train_loader, criterion, optimizer, num_epochs=30)\n",
    "\n",
    "        # Evaluate the model\n",
    "        evaluate_model(model, test_loader)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
